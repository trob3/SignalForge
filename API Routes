import io
from typing import List

import pandas as pd
from fastapi import APIRouter, File, HTTPException, UploadFile
from pydantic import BaseModel

from signalforge.core.normalization import normalize_alerts_df
from signalforge.core.scoring import score_detections, RuleScore

router = APIRouter(prefix="/v1")

MAX_BYTES = 10 * 1024 * 1024  # 10MB
ALLOWED_CONTENT_TYPES = {"text/csv", "application/csv", "text/plain"}


class DetectionScore(BaseModel):
    """API response schema — deliberately decoupled from the internal RuleScore dataclass."""
    rule_id:                 str
    rule_name:               str
    alerts:                  int
    detection_quality_score: float
    false_positive_rate:     float
    true_positive_rate:      float
    avg_duplication_factor:  float
    avg_ttc_factor:          float
    avg_confidence:          float
    tuning_priority:         str

    @classmethod
    def from_rule_score(cls, r: RuleScore) -> "DetectionScore":
        return cls(
            rule_id=r.rule_id,
            rule_name=r.rule_name,
            alerts=r.alerts,
            detection_quality_score=r.detection_quality_score,
            false_positive_rate=r.false_positive_rate,
            true_positive_rate=r.true_positive_rate,
            avg_duplication_factor=r.avg_duplication_factor,
            avg_ttc_factor=r.avg_ttc_factor,
            avg_confidence=r.avg_confidence,
            tuning_priority=r.tuning_priority,
        )


@router.post(
    "/score/csv",
    response_model=List[DetectionScore],
    summary="Score detections from a CSV alert export",
    description="Upload a CSV exported from Sentinel, Splunk, or Security Hub. "
                "Returns a Detection Quality Score (0–100) per rule.",
)
async def score_csv(file: UploadFile = File(...)) -> List[DetectionScore]:
    # --- Validate file type ---
    if not file.filename.lower().endswith(".csv"):
        raise HTTPException(status_code=400, detail="File must have a .csv extension.")
    if file.content_type and file.content_type not in ALLOWED_CONTENT_TYPES:
        raise HTTPException(
            status_code=415,
            detail=f"Unsupported content type '{file.content_type}'. Expected a CSV.",
        )

    # --- Read & enforce size limit ---
    raw = await file.read()
    if len(raw) > MAX_BYTES:
        raise HTTPException(
            status_code=413,
            detail=f"File too large. Maximum allowed size is {MAX_BYTES // (1024 * 1024)}MB.",
        )
    if len(raw) == 0:
        raise HTTPException(status_code=400, detail="Uploaded file is empty.")

    # --- Parse CSV ---
    try:
        df = pd.read_csv(io.BytesIO(raw))
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"Could not parse CSV: {e}")

    if df.empty:
        raise HTTPException(status_code=422, detail="CSV parsed successfully but contains no data rows.")

    # --- Normalize ---
    try:
        norm = normalize_alerts_df(df)
    except KeyError as e:
        raise HTTPException(
            status_code=422,
            detail=f"CSV is missing a required column: {e}. "
                   "Ensure your export includes rule_name, disposition, and closed_at fields.",
        )
    except ValueError as e:
        raise HTTPException(status_code=422, detail=f"Normalization error: {e}")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Unexpected error during normalization: {e}")

    # --- Score ---
    try:
        result = score_detections(norm)
    except KeyError as e:
        raise HTTPException(status_code=422, detail=f"Scoring failed — missing field: {e}")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Unexpected error during scoring: {e}")

    if not result.per_rule:
        raise HTTPException(status_code=422, detail="Scoring produced no results. Check your input data.")

    return [DetectionScore.from_rule_score(r) for r in result.per_rule]
